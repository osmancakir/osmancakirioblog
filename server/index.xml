<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>osman cakir</title>
    <link>https://osmancakir.io/</link>
    <description>Recent content on osman cakir</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://osmancakir.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CNNs - The VGG16 Model with Keras Simple Prediction</title>
      <link>https://osmancakir.io/deep_learning/cnns_vgg16_keras_simplest/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/deep_learning/cnns_vgg16_keras_simplest/</guid>
      <description>In this notebook we are just going to look at the VGG16 model and try a simple prediction with a now unfortunately extinct Kauai &amp;lsquo;O&amp;rsquo;o bird&amp;rsquo;s photo.
The sweet, bell-like tones of the Kauai O&amp;rsquo;o were heard for the last time nearly 20 years ago. Below through the link you can listen to its sad song.

Let&amp;rsquo;s also look at the photo I am going to use for this example.</description>
    </item>
    
    <item>
      <title>A Personal Historical Revision</title>
      <link>https://osmancakir.io/articles/historical_revision/</link>
      <pubDate>Sun, 02 Dec 2018 11:53:49 -0700</pubDate>
      
      <guid>https://osmancakir.io/articles/historical_revision/</guid>
      <description>To be honest, I do not know exactly if I am writing this essay to make sense of my past. As the usual, I feel the need to sit down, take the pen in my hand and write, but don&amp;rsquo;t know how to start or even how to plan what I am going to write. It is more like my past is forcing me to write this. Sounds a lot like a scene from the Looper(2012) film.</description>
    </item>
    
    <item>
      <title>Introduction to Spark and Python</title>
      <link>https://osmancakir.io/big_data/spark_and_python_introduction/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/big_data/spark_and_python_introduction/</guid>
      <description>Let&amp;rsquo;s learn how to use Spark with Python by using the pyspark library!
Creating a SparkContext First we need to create a SparkContext. We will import this from pyspark:
from pyspark import SparkContext Now create the SparkContext,A SparkContext represents the connection to a Spark cluster, and can be used to create an RDD and broadcast variables on that cluster.
Note! You can only have one SparkContext at a time the way we are running things here.</description>
    </item>
    
    <item>
      <title>K Means Clustering University Clusters</title>
      <link>https://osmancakir.io/learning_unsupervised/k_means_clustering_university_clusters/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/learning_unsupervised/k_means_clustering_university_clusters/</guid>
      <description>We will attempt to use KMeans Clustering to cluster Universities into to two groups, Private and Public.
It is very important to note, we actually have the labels for this data set, but we will NOT use them for the KMeans clustering algorithm, since that is an unsupervised learning algorithm.
When using the Kmeans algorithm under normal circumstances, it is because you don&amp;rsquo;t have labels. In this case we will use the labels to try to get an idea of how well the algorithm performed, but you won&amp;rsquo;t usually do this for Kmeans, so the classification report and confusion matrix at the end of this project, don&amp;rsquo;t truly make sense in a real world setting!</description>
    </item>
    
    <item>
      <title>K Nearest Neighbors Classified Target Prediction</title>
      <link>https://osmancakir.io/supervised_learning/k_nearest_neighbors_classifed_target_prediction/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/supervised_learning/k_nearest_neighbors_classifed_target_prediction/</guid>
      <description>Let&amp;rsquo;s start by importing necessary libraries for this project
import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline Get the Data ** Read the &amp;lsquo;KNN_Project_Data csv file into a dataframe **
df = pd.read_csv(&amp;#39;KNN_Project_Data&amp;#39;) Check the head of the dataframe.
df.head()     XVPM GWYH TRAT TLLZ IGGA HYKR EDFS GUUB MGJM JHZC TARGET CLASS     0 1636.</description>
    </item>
    
    <item>
      <title>Linear Regression Ecommerce Consultation</title>
      <link>https://osmancakir.io/supervised_learning/linear_regression_ecommerce_consultation/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/supervised_learning/linear_regression_ecommerce_consultation/</guid>
      <description>Assume you just signed a contract with an E-commerce company based in Munich. Customers can buy clothes either on a mobile app or a website for the clothes they want. The company has also a styling store where customers can come and have sessions with a personal stylist.
The company is trying to decide whether to focus their efforts on their mobile app experience or their website. Your job is to help them figure it out.</description>
    </item>
    
    <item>
      <title>NLP Yelp Reviews</title>
      <link>https://osmancakir.io/nlp/nlp_yelp_reviews/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/nlp/nlp_yelp_reviews/</guid>
      <description>In this NLP project, we will be attempting to classify Yelp Reviews into 1 star or 5 star categories based on the text content in the reviews. We will also build a data pipeline that will help us automate the preparation and analytics of the data.
We will use the Yelp Review Data Set from Kaggle.
Each observation in this dataset is a review of a particular business by a particular user.</description>
    </item>
    
    <item>
      <title>Principal Component Analysis for Doctors</title>
      <link>https://osmancakir.io/learning_unsupervised/principal_component_analysis_for_doctors/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/learning_unsupervised/principal_component_analysis_for_doctors/</guid>
      <description>Start by importing the necessary libraries for this project import matplotlib.pyplot as plt import pandas as pd import numpy as np import seaborn as sns %matplotlib inline The Data Let&amp;rsquo;s work with the cancer data set.
from sklearn.datasets import load_breast_cancercancer = load_breast_cancer()cancer.keys() dict_keys([&#39;DESCR&#39;, &#39;data&#39;, &#39;feature_names&#39;, &#39;target_names&#39;, &#39;target&#39;])  print(cancer[&amp;#39;DESCR&amp;#39;]) Breast Cancer Wisconsin (Diagnostic) Database Notes ----- Data Set Characteristics: :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.</description>
    </item>
    
    <item>
      <title>Python 1 : Introduction</title>
      <link>https://osmancakir.io/python/python_1_introduction/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/python/python_1_introduction/</guid>
      <description>Python started as a fun project by a dutch guy who got bored on a Christmas Holiday. Check out this guy. He is cool. Guido van Rossum
Anyways we are going to do some basic calculations, introducing variables and data types in this introduction tutorial.
Let&amp;rsquo;s Start I am psyched!
Calculations As you can guess basic calculation operators are : summing: &amp;lsquo; + &amp;lsquo;, subtracting: &amp;lsquo; - &amp;lsquo;, Multiplying: &amp;lsquo; * &amp;lsquo; Division: &amp;lsquo; / &amp;lsquo;, Exponentiation: &amp;lsquo; ** &amp;lsquo;, and Modulo: &amp;lsquo; % &amp;rsquo; (Which is the operation for giving you the result of the reminder of a division)</description>
    </item>
    
    <item>
      <title>Python 2 : Manipulating Lists</title>
      <link>https://osmancakir.io/python/python_2_manipulating_lists/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/python/python_2_manipulating_lists/</guid>
      <description>First let&amp;rsquo;s create a list called cars
cars=[&amp;#39;porsche&amp;#39;,60, &amp;#39;audi&amp;#39;,37, &amp;#39;mercedes&amp;#39;, 45, &amp;#39;bmw&amp;#39;,43, &amp;#39;vw&amp;#39;, 32] Changing Elements is easy. Call the element by it&amp;rsquo;s index and equal to something else.
cars[8]=&amp;#39;skoda&amp;#39;cars [&#39;porsche&#39;, 60, &#39;audi&#39;, 37, &#39;mercedes&#39;, 45, &#39;bmw&#39;, 43, &#39;skoda&#39;, 32]  You can change multiple entries analoguously.
cars[8:]=[&amp;#39;fiat&amp;#39;,22]cars [&#39;porsche&#39;, 60, &#39;audi&#39;, 37, &#39;mercedes&#39;, 45, &#39;bmw&#39;, 43, &#39;fiat&#39;, 22]  Adding Elements might be even easier. Just call your list and add something to it.</description>
    </item>
    
    <item>
      <title>Python 3 : Functions, Loops, Lambdas</title>
      <link>https://osmancakir.io/python/python_3_functions_loops_lambdas/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/python/python_3_functions_loops_lambdas/</guid>
      <description>Please note, this is not meant to be a comprehensive overview of Python or programming in general, but this crash course covers the basics that you need to know when you work with the data. I am planning to provide some more python learning material that focuses on more of the software development topics too. However for now here we focus on data science aspects of it.
Since I do not want to divide the topic into more sub topics any more, this notebook will be a little bit long and we will cover many stuff.</description>
    </item>
    
    <item>
      <title>Python 4 : Data Analysis with Numpy</title>
      <link>https://osmancakir.io/python/python_4_data_analysis_with_numpy/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/python/python_4_data_analysis_with_numpy/</guid>
      <description>We will have 3 big sections on NumPy.
 1 - NumPy Introduction 2 - NumPy Indextion and Selection 3 - NumPy Operations  1 - NumPy Introduction Installation Instructions It is highly recommended you install Python using the Anaconda distribution to make sure all underlying dependencies (such as Linear Algebra libraries) all sync up with the use of a conda install. If you have Anaconda, install NumPy by going to your terminal or command prompt and typing:</description>
    </item>
    
    <item>
      <title>Random Forests Debt Defaults</title>
      <link>https://osmancakir.io/supervised_learning/random_forests_debt_defaults/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/supervised_learning/random_forests_debt_defaults/</guid>
      <description>For this project we will be exploring publicly available data from LendingClub.com. Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back. We will try to create a model that will help predict this.
We will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full.</description>
    </item>
    
    <item>
      <title>Recommender Systems Basics Recommending Films</title>
      <link>https://osmancakir.io/recommender_systems/recommender_systems_basics_recommending_films/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/recommender_systems/recommender_systems_basics_recommending_films/</guid>
      <description>In this basic project, we will focus on providing a basic recommendation system by suggesting items that are most similar to a particular item, in this case, films. Keep in mind, this is not a true robust recommendation system, to describe it more accurately,it just tells you what movies/items are most similar to your movie choice.
Let&amp;rsquo;s get started!
Import Libraries import numpy as np import pandas as pd Get the Data column_names = [&amp;#39;user_id&amp;#39;, &amp;#39;item_id&amp;#39;, &amp;#39;rating&amp;#39;, &amp;#39;timestamp&amp;#39;] df = pd.</description>
    </item>
    
    <item>
      <title>Support Vector Machines Iris Dataset</title>
      <link>https://osmancakir.io/supervised_learning/support_vector_machines_iris_dataset/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/supervised_learning/support_vector_machines_iris_dataset/</guid>
      <description>We will be analyzing the famous iris data set in this small project!
The Data For this series of lectures, we will be using the famous Iris flower data set.
The Iris flower data set or Fisher&amp;rsquo;s Iris data set is a multivariate data set introduced by Sir Ronald Fisher in the 1936 as an example of discriminant analysis.
The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor), so 150 total samples.</description>
    </item>
    
    <item>
      <title>Logistic Regression Online Ads</title>
      <link>https://osmancakir.io/supervised_learning/logistic_regression_online_ads/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://osmancakir.io/supervised_learning/logistic_regression_online_ads/</guid>
      <description>In this project we will be working with a fake advertising data set, indicating whether or not a particular internet user clicked on an Advertisement on a company website. We will try to create a model that will predict whether or not they will click on an ad based off the features of that user.
This data set contains the following features:
 &amp;lsquo;Daily Time Spent on Site&amp;rsquo;: consumer time on site in minutes &amp;lsquo;Age&amp;rsquo;: cutomer age in years &amp;lsquo;Area Income&amp;rsquo;: Avg.</description>
    </item>
    
    <item>
      <title>About Osman Cakir</title>
      <link>https://osmancakir.io/about/osman_cakir/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://osmancakir.io/about/osman_cakir/</guid>
      <description>As someone with diverse interests, I am trying to maintain a peaceful life with lots of books, films, a little bit music on the side. Without comparing myself to anyone, I try to get (and give) as much as love, laughter and an understanding how things work and evolve around me. I help organizing a Turkish film festival in Munich. I like djing electronica/downtempo music with melodic warmth. My favourite activity is sitting on a bench somewhere in the city listening to the wave of thoughts in my mind quietly while enjoying my coffee.</description>
    </item>
    
  </channel>
</rss>